{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Articles used to help create this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/neo4j/langchain-library-adds-full-support-for-neo4j-vector-index-fa94b8eab334\n",
    "# https://medium.com/towards-data-science/efficient-semantic-search-over-unstructured-text-in-neo4j-8179ad7ff451\n",
    "# https://frodnar.github.io/posts/2023-09-30_building_llm_chatbot_neo4j/\n",
    "# https://python.langchain.com/docs/integrations/vectorstores/neo4jvector\n",
    "# https://python.langchain.com/docs/use_cases/more/graph/graph_cypher_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST STEP - Load the database dump into Neo4j Aura DB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Required Libraries & Connect to APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Neo4jVector\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.docstore.document import Document\n",
    "import pandas as pd\n",
    "from langchain.graphs import Neo4jGraph\n",
    "import os\n",
    "import openai\n",
    "from neo4j import GraphDatabase\n",
    "from graphdatascience import GraphDataScience\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "import umap\n",
    "from sklearn.cluster import KMeans\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"neo4j+s://483c47f7.databases.neo4j.io\"\n",
    "username = \"neo4j\"\n",
    "password = \"\"\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=url,\n",
    "    username=username,\n",
    "    password=password\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = \"\"\n",
    "openai.api_key = openai_api_key\n",
    "# openai.Model.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(url, auth=(username, password))\n",
    "session = driver.session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grab a document and check to see if it's chunked or if the whole document has been embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(query):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query)\n",
    "        return pd.DataFrame([r.values() for r in result], columns=result.keys())\n",
    "\n",
    "# Now use the function to get a DataFrame:\n",
    "df = get_dataframe(\"MATCH (a) RETURN id(a) LIMIT 1\")\n",
    "driver.close()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"MATCH (a:Document) RETURN count(a) as Number_Documets LIMIT 1\"\n",
    "\n",
    "df = get_dataframe(q)\n",
    "driver.close()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "MATCH (a:Document)\n",
    "RETURN substring(toString(a.date), 0, 4) AS Year, count(a) AS Number_Documents_by_Year\n",
    "ORDER BY Year\n",
    "\"\"\"\n",
    "\n",
    "df = get_dataframe(q)\n",
    "driver.close()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "MATCH (a:Topic)<-[r:IS_IN]-(b:Document)\n",
    "RETURN a.name as Topic_Name, count(b) as topic_count\n",
    "ORDER BY topic_count DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "df = get_dataframe(q)\n",
    "driver.close()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "MATCH (a:Document)-[r:ASSIGNED_TO]->(b)\n",
    "//WHERE b.name CONTAINS ('Bank')\n",
    "RETURN b.name as Assignee_Name, count(a) as document_count\n",
    "ORDER BY document_count DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "df = get_dataframe(q)\n",
    "driver.close()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "MATCH (c:Topic)<-[r2:IS_IN]-(a:Document)-[r:ASSIGNED_TO]->(b)\n",
    "//WHERE b.name CONTAINS ('Bank')\n",
    "RETURN b.name as Assignee_Name, c.name as Topic_Name, count(a) as document_count\n",
    "ORDER BY document_count DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "df = get_dataframe(q)\n",
    "driver.close()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "MATCH (c:Topic)<-[r2:IS_IN]-(a:Document)-[r:ASSIGNED_TO]->(b)\n",
    "WHERE b.name = 'MICROSOFT TECHNOLOGY LICENSING, LLC'\n",
    "RETURN a.abstract\n",
    "\"\"\"\n",
    "\n",
    "df = get_dataframe(q)\n",
    "driver.close()\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[0, 'a.abstract'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather data to send to ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "MATCH (c:Topic)<-[r2:IS_IN]-(a:Document)-[r:ASSIGNED_TO]->(b:Assignee)\n",
    "WHERE c.name = 'Machine Learning'\n",
    "RETURN id(a) as ida\n",
    ", a.title as Patent_Title \n",
    ", b.name as Patent_Owner\n",
    ", a.abstract as Patent_Abstract\n",
    "LIMIT 300\n",
    "\"\"\"\n",
    "\n",
    "df = get_dataframe(q)\n",
    "driver.close()\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_abstract(abstract_text):\n",
    "    response = openai.Completion.create(\n",
    "      model=\"text-davinci-002\", \n",
    "      prompt=f\"Summarize the following patent abstract in laymen's terms in fewer than 100 tokens: {abstract_text}\",\n",
    "      max_tokens=100\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Loop through the dataframe and apply the summary function\n",
    "df['Summary'] = df['Patent_Abstract'].apply(summarize_abstract)\n",
    "\n",
    "# Display the updated dataframe with summaries\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the response from ChatGPT\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df['Summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the summaries back to Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update node summary\n",
    "def update_node_summary(session, node_id, summary):\n",
    "    query = \"\"\"\n",
    "    MATCH (a:Document) \n",
    "    WHERE id(a) = $node_id\n",
    "    SET a.Summary = $summary\n",
    "    \"\"\"\n",
    "    session.run(query, node_id=node_id, summary=summary)\n",
    "\n",
    "# Loop through DataFrame and update each node\n",
    "with driver.session() as session:\n",
    "    for index, row in df.iterrows():\n",
    "        node_id = row['ida']\n",
    "        summary = row['Summary']\n",
    "        update_node_summary(session, node_id, summary)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = f\"\"\"MATCH (a:Document) \n",
    "    WHERE a.Summary is not null\n",
    "    RETURN id(a) as ida, a.Summary as Summary\n",
    "    \"\"\"\n",
    "\n",
    "df = get_dataframe(q)\n",
    "driver.close()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = df['Summary'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_indices = [i for i, summary in enumerate(summaries) if not summary or pd.isna(summary)]\n",
    "print(empty_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summaries[140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 10000,\n",
    "    chunk_overlap  = 0,\n",
    "    length_function = len,\n",
    "    add_start_index = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = text_splitter.create_documents(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.query(\"\"\"\n",
    "CALL db.index.vector.createNodeIndex(\n",
    "  'patent_summary_embeddings', // index name\n",
    "  'Chunk',                     // node label\n",
    "  'embedding',                 // node property\n",
    "   1536,                       // vector size\n",
    "   'cosine'                    // similarity metric\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_vector = Neo4jVector.from_documents(\n",
    "    texts,\n",
    "    OpenAIEmbeddings(),\n",
    "    url=url,\n",
    "    username=username,\n",
    "    password=password\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query / Return Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = f\"\"\"MATCH (a:Chunk) \n",
    "    RETURN id(a) as ida\n",
    "    , a.embedding as Embedding\n",
    "    , a.text as Text\n",
    "    \"\"\"\n",
    "\n",
    "df = get_dataframe(q)\n",
    "driver.close()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
